{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "rs_assignment_2-4.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dAQpYjPVzdsw"
      },
      "source": [
        "# Recommendation Systems Assignment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GUjvLryBzdsx"
      },
      "source": [
        "### MIE451/1513 UofT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "T8rWqpOEzdsz"
      },
      "source": [
        "### Getting MovieLens data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PQaV4DkBzds0"
      },
      "source": [
        "* Download the movielens 100k dataset from this link: [ml-100k.zip](http://files.grouplens.org/datasets/movielens/ml-100k.zip)\n",
        "\n",
        "* Upload ml-100k.zip\n",
        "\n",
        "* Extract using the following cell:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "R9dHQTK1zds1"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xncf3xm1zds2",
        "outputId": "ddf12d54-c05b-4382-efa8-e02a17c424cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 259
        }
      },
      "source": [
        "# import required libraries\n",
        "!pip install wget\n",
        "import os\n",
        "import os.path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from math import sqrt\n",
        "from heapq import nlargest\n",
        "from tqdm import trange\n",
        "from tqdm import tqdm\n",
        "from scipy import stats\n",
        "from sklearn.metrics.pairwise import pairwise_distances\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import wget"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wget\n",
            "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-cp36-none-any.whl size=9682 sha256=913caa9415e21305662681756751778932b70dba8d9356ca5dfb34217769fc55\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "F1ill6yOzds5"
      },
      "source": [
        "## Support functions and variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lNbQGMevzds8",
        "outputId": "338b4bf1-dafb-48fb-f6a6-ef4e5faa6f8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 913
        }
      },
      "source": [
        "wget.download(\"https://github.com/MIE451-1513-2019/course-datasets/raw/master/ml-100k.zip\")\n",
        "!unzip ml-100k.zip\n",
        "MOVIELENS_DIR = \"ml-100k\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  ml-100k.zip\n",
            "   creating: ml-100k/\n",
            "  inflating: ml-100k/u.item          \n",
            "   creating: __MACOSX/\n",
            "   creating: __MACOSX/ml-100k/\n",
            "  inflating: __MACOSX/ml-100k/._u.item  \n",
            "  inflating: ml-100k/u3.test         \n",
            "  inflating: __MACOSX/ml-100k/._u3.test  \n",
            "  inflating: ml-100k/u1.base         \n",
            "  inflating: __MACOSX/ml-100k/._u1.base  \n",
            "  inflating: ml-100k/u.info          \n",
            "  inflating: __MACOSX/ml-100k/._u.info  \n",
            "  inflating: ml-100k/u2.test         \n",
            "  inflating: __MACOSX/ml-100k/._u2.test  \n",
            "  inflating: ml-100k/u5.test         \n",
            "  inflating: __MACOSX/ml-100k/._u5.test  \n",
            "  inflating: ml-100k/u.genre         \n",
            "  inflating: __MACOSX/ml-100k/._u.genre  \n",
            "  inflating: ml-100k/ub.test         \n",
            "  inflating: __MACOSX/ml-100k/._ub.test  \n",
            "  inflating: ml-100k/ua.base         \n",
            "  inflating: __MACOSX/ml-100k/._ua.base  \n",
            "  inflating: ml-100k/u.data          \n",
            "  inflating: __MACOSX/ml-100k/._u.data  \n",
            "  inflating: ml-100k/README          \n",
            "  inflating: __MACOSX/ml-100k/._README  \n",
            "  inflating: ml-100k/u4.test         \n",
            "  inflating: __MACOSX/ml-100k/._u4.test  \n",
            "  inflating: ml-100k/u5.base         \n",
            "  inflating: __MACOSX/ml-100k/._u5.base  \n",
            "  inflating: ml-100k/ub.base         \n",
            "  inflating: __MACOSX/ml-100k/._ub.base  \n",
            "  inflating: ml-100k/ua.test         \n",
            "  inflating: __MACOSX/ml-100k/._ua.test  \n",
            "  inflating: ml-100k/u4.base         \n",
            "  inflating: __MACOSX/ml-100k/._u4.base  \n",
            "  inflating: ml-100k/u.user          \n",
            "  inflating: __MACOSX/ml-100k/._u.user  \n",
            "  inflating: ml-100k/allbut.pl       \n",
            "  inflating: __MACOSX/ml-100k/._allbut.pl  \n",
            "  inflating: ml-100k/u3.base         \n",
            "  inflating: __MACOSX/ml-100k/._u3.base  \n",
            "  inflating: ml-100k/u1.test         \n",
            "  inflating: __MACOSX/ml-100k/._u1.test  \n",
            "  inflating: ml-100k/mku.sh          \n",
            "  inflating: __MACOSX/ml-100k/._mku.sh  \n",
            "  inflating: ml-100k/u2.base         \n",
            "  inflating: __MACOSX/ml-100k/._u2.base  \n",
            "  inflating: ml-100k/u.occupation    \n",
            "  inflating: __MACOSX/ml-100k/._u.occupation  \n",
            "  inflating: __MACOSX/._ml-100k      \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "emOWqsTGzdtB",
        "outputId": "fe6f8382-f56a-407f-9ed1-baba0ad98b68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 97
        }
      },
      "source": [
        "!ls {MOVIELENS_DIR}"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "allbut.pl  u1.base  u2.test  u4.base  u5.test  ub.base\tu.genre  u.occupation\n",
            "mku.sh\t   u1.test  u3.base  u4.test  ua.base  ub.test\tu.info\t u.user\n",
            "README\t   u2.base  u3.test  u5.base  ua.test  u.data\tu.item\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3k0-kPF7zdtE",
        "colab": {}
      },
      "source": [
        "def getData(folder_path, file_name):\n",
        "    fields = ['userID', 'itemID', 'rating', 'timestamp']\n",
        "    data = pd.read_csv(os.path.join(folder_path, file_name), sep='\\t', names=fields)\n",
        "    return data "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nvqWuW5NzdtI",
        "colab": {}
      },
      "source": [
        "rating_df = getData(MOVIELENS_DIR, 'u.data')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5RPCAd--22MQ",
        "outputId": "68142a5a-6dbd-4e76-a8cb-389e494e7794",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "rating_df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userID</th>\n",
              "      <th>itemID</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>196</td>\n",
              "      <td>242</td>\n",
              "      <td>3</td>\n",
              "      <td>881250949</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>186</td>\n",
              "      <td>302</td>\n",
              "      <td>3</td>\n",
              "      <td>891717742</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>22</td>\n",
              "      <td>377</td>\n",
              "      <td>1</td>\n",
              "      <td>878887116</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>244</td>\n",
              "      <td>51</td>\n",
              "      <td>2</td>\n",
              "      <td>880606923</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>166</td>\n",
              "      <td>346</td>\n",
              "      <td>1</td>\n",
              "      <td>886397596</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   userID  itemID  rating  timestamp\n",
              "0     196     242       3  881250949\n",
              "1     186     302       3  891717742\n",
              "2      22     377       1  878887116\n",
              "3     244      51       2  880606923\n",
              "4     166     346       1  886397596"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SpmN2NrTzdtK",
        "outputId": "c2c315cf-c0e0-4a03-e816-e684007004b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "num_users = len(rating_df.userID.unique())\n",
        "num_items = len(rating_df.itemID.unique())\n",
        "print(\"Number of users:\", num_users)\n",
        "print(\"Number of items:\", num_items)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of users: 943\n",
            "Number of items: 1682\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GQg7fW9SzdtO"
      },
      "source": [
        "## Q1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jLVaLm25zdtO"
      },
      "source": [
        "### (a) Building User-to-Item Rating Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FiiG_0QfzdtP",
        "colab": {}
      },
      "source": [
        "def dataPreprocessor(rating_df, num_users, num_items):\n",
        "    \"\"\"\n",
        "        INPUT: \n",
        "            data: pandas DataFrame. columns=['userID', 'itemID', 'rating' ...]\n",
        "            num_row: int. number of users\n",
        "            num_col: int. number of items\n",
        "            \n",
        "        OUTPUT:\n",
        "            matrix: 2D numpy array. \n",
        "            \n",
        "        NOTE 1: see where something very similar is done in the lab in function 'buildUserItemMatrix'    \n",
        "            \n",
        "        NOTE 2: data can have more columns, but your function should ignore \n",
        "              additional columns.\n",
        "    \"\"\"\n",
        "    # Initialize a of size (numUsers, numItems) to zeros\n",
        "    matrix = np.zeros((num_users, num_items), dtype=np.int8)\n",
        "    \n",
        "    # Populate the matrix based on the dataset\n",
        "    for (index, userID, itemID, rating, timestamp) in rating_df.itertuples():\n",
        "        matrix[userID-1, itemID-1] = rating\n",
        "\n",
        "    return matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "f6DxbgBmzdtS",
        "outputId": "ea42d486-bb35-4261-b229-e956945f5288",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "dataPreprocessor(rating_df, num_users, num_items)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5, 3, 4, ..., 0, 0, 0],\n",
              "       [4, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [5, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 5, 0, ..., 0, 0, 0]], dtype=int8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4b4XZHBczdtU"
      },
      "source": [
        "### (b) User Average/Popularity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "z9AkrRvUzdtV",
        "colab": {}
      },
      "source": [
        "class BaseLineRecSys(object):\n",
        "    def __init__(self, method, processor=dataPreprocessor):\n",
        "        \"\"\"\n",
        "            method: string. From ['popularity','useraverage']\n",
        "            processor: function name. dataPreprocessor by default\n",
        "        \"\"\"\n",
        "        self.method_name = method #4\n",
        "        self.method = self._getMethod(self.method_name) #3 train_matrix, num_users, num_items\n",
        "        self.processor = processor #2\n",
        "        self.pred_column_name = self.method_name #evaluate2\n",
        "        \n",
        "    def _getMethod(self, method_name): #5\n",
        "        \"\"\"\n",
        "            Don't change this\n",
        "        \"\"\"\n",
        "        switcher = {\n",
        "            'popularity': self.popularity,\n",
        "            'useraverage': self.useraverage,\n",
        "        }\n",
        "        \n",
        "        return switcher[method_name]\n",
        "    \n",
        "    @staticmethod\n",
        "    def useraverage(train_matrix, num_users, num_items): #6 average rating the user has given\n",
        "        \"\"\"\n",
        "            INPUT:\n",
        "                train_matrix: 2D numpy array.\n",
        "                num_users: int. Number of Users.\n",
        "                num_items: int. Number of Items.\n",
        "            OUTPUT:\n",
        "                predictionMatrix: 2D numpy array.\n",
        "                \n",
        "            NOTE: see where something very similar is done in the lab in function 'predictByUserAverage'    \n",
        "        \"\"\"\n",
        "        \n",
        "        predictionMatrix = np.zeros((num_users, num_items))\n",
        "        for (user, item), rating in np.ndenumerate(train_matrix):\n",
        "            # Predict rating for every item that wasn't ranked by the user (rating == 0)\n",
        "            if rating == 0:\n",
        "                # select the row for user\n",
        "                # what's the shape of userVector 1*number of all items\n",
        "                userVector = train_matrix[user, :]\n",
        "                ratedItems = userVector[userVector.nonzero()] #itemsha that have been rated by this user \n",
        "                #matrix.nonzero Return the indices of the elements that are non-zero.\n",
        "                \n",
        "                # If not empty, calculate average and set as rating for the current item\n",
        "                if ratedItems.size == 0:\n",
        "                    average_item = 0 \n",
        "                else:\n",
        "                    average_item = ratedItems.mean()\n",
        "                predictionMatrix[user,item] = average_item\n",
        "            \n",
        "            # report progress every 100 users\n",
        "            if (user % 100 == 0 and item == 1):\n",
        "                print (\"calculated %d users\" % (user,))\n",
        "    \n",
        "        return predictionMatrix\n",
        "    \n",
        "    @staticmethod\n",
        "    def popularity(train_matrix, num_users, num_items): #6 all items that do not have a rating will get a rating based \n",
        "    #on all user ratings of the item\n",
        "        \"\"\"\n",
        "            INPUT:\n",
        "                train_matrix: 2D numpy array.\n",
        "                num_users: int. Number of Users.\n",
        "                num_items: int. Number of Items.\n",
        "            OUTPUT:\n",
        "                predictionMatrix: 2D numpy array.\n",
        "                \n",
        "            NOTE: see where something very similar is done in the lab in function 'predictByPopularity'    \n",
        "        \"\"\"\n",
        "        \n",
        "        predictionMatrix = np.zeros((num_users, num_items))\n",
        "       \n",
        "        # Define function for converting 1-5 rating to 0/1 (like / don't like)\n",
        "        vp = np.vectorize(lambda x: 1 if x >= 4 else 0)\n",
        "\n",
        "        # For every item calculate the number of people liked (4-5) divided by the number of people that rated  \n",
        "        itemPopularity = np.zeros((num_items))\n",
        "\n",
        "        for item in range(num_items):\n",
        "            NumberOfUserRated = len(train_matrix[:,item].nonzero()[0])\n",
        "            NumberOfUserLiked = len((vp(train_matrix[:, item]).nonzero()[0]))\n",
        "\n",
        "            if NumberOfUserRated == 0:\n",
        "                itemPopularity[item] = 0\n",
        "            else:\n",
        "                itemPopularity[item] = NumberOfUserLiked/NumberOfUserRated\n",
        "    \n",
        "        for (user,item), rating in np.ndenumerate(train_matrix):\n",
        "            # Predict rating for every item that wasn't ranked by the user (rating == 0)\n",
        "            if rating == 0:\n",
        "                predictionMatrix[user, item] = itemPopularity[item]\n",
        "            \n",
        "            # report progress every 100 users\n",
        "            if (user % 100 == 0 and item == 1):\n",
        "                print (\"calculated %d users\" % (user,))\n",
        "\n",
        "        return predictionMatrix    \n",
        "    \n",
        "    def predict_all(self, train_df, num_users, num_items): #1\n",
        "        \n",
        "        train_matrix = self.processor(train_df, num_users, num_items) #User-to-Item Rating Matrix\n",
        "        self.__model = self.method(train_matrix, num_users, num_items) #return the prediction matrix\n",
        "        \n",
        "    def evaluate_test(self, test_df, copy=False):  #evaluate1\n",
        "        \n",
        "        if copy:\n",
        "            prediction = test_df.copy()\n",
        "        else:\n",
        "            prediction = test_df\n",
        "            \n",
        "        prediction[self.pred_column_name] = np.nan #one of the two methods ['useraverge'] = 0\n",
        "        \n",
        "        for (index, \n",
        "             userID, \n",
        "             itemID) in tqdm(prediction[['userID','itemID']].itertuples()):\n",
        "            prediction.loc[index, self.pred_column_name] = self.__model[userID-1, itemID-1] #prediction matrix user--roll, item-- column\n",
        "\n",
        "        return prediction\n",
        "        \n",
        "    def getModel(self): #7 get from predict_all, return the prediction model\n",
        "        \"\"\"\n",
        "            return predicted user-item matrix\n",
        "        \"\"\"\n",
        "        return self.__model\n",
        "    \n",
        "    def getPredColName(self):\n",
        "        \"\"\"\n",
        "            return prediction column name\n",
        "        \"\"\"\n",
        "        return self.pred_column_name\n",
        "    \n",
        "    def reset(self):\n",
        "        \"\"\"\n",
        "            reuse the instance of the class by removing model\n",
        "        \"\"\"\n",
        "        try:\n",
        "            self.model = None\n",
        "        except:\n",
        "            print(\"You don not have model..\")\n",
        "            "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XgDw3ALnzdtX",
        "colab": {}
      },
      "source": [
        "popularity_recsys = BaseLineRecSys('popularity')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wJd50FSdzdta",
        "outputId": "c721c0be-3679-47fc-c1c4-6f2c668d1658",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "popularity_recsys.predict_all(rating_df, num_users, num_items)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n",
            "calculated 800 users\n",
            "calculated 900 users\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "C5TJkUaszdtc",
        "colab": {}
      },
      "source": [
        "x = popularity_recsys.getModel()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HN8r3Obtzdtg",
        "outputId": "c5be6aaf-7e50-4457-ee4b-3ecd70bb92e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "np.all(x<=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oZDsDg5Gzdtj",
        "outputId": "6603c719-cc18-4c23-bb06-3a14ad1cf7e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "rating_df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userID</th>\n",
              "      <th>itemID</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>196</td>\n",
              "      <td>242</td>\n",
              "      <td>3</td>\n",
              "      <td>881250949</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>186</td>\n",
              "      <td>302</td>\n",
              "      <td>3</td>\n",
              "      <td>891717742</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>22</td>\n",
              "      <td>377</td>\n",
              "      <td>1</td>\n",
              "      <td>878887116</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>244</td>\n",
              "      <td>51</td>\n",
              "      <td>2</td>\n",
              "      <td>880606923</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>166</td>\n",
              "      <td>346</td>\n",
              "      <td>1</td>\n",
              "      <td>886397596</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   userID  itemID  rating  timestamp\n",
              "0     196     242       3  881250949\n",
              "1     186     302       3  891717742\n",
              "2      22     377       1  878887116\n",
              "3     244      51       2  880606923\n",
              "4     166     346       1  886397596"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "p60BEmn-zdtm",
        "outputId": "7269b94f-05c4-4e4e-fbad-ed16496ccce3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        }
      },
      "source": [
        "popularity_recsys.evaluate_test(rating_df,copy=True).head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100000it [01:25, 1168.98it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userID</th>\n",
              "      <th>itemID</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>popularity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>196</td>\n",
              "      <td>242</td>\n",
              "      <td>3</td>\n",
              "      <td>881250949</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>186</td>\n",
              "      <td>302</td>\n",
              "      <td>3</td>\n",
              "      <td>891717742</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>22</td>\n",
              "      <td>377</td>\n",
              "      <td>1</td>\n",
              "      <td>878887116</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>244</td>\n",
              "      <td>51</td>\n",
              "      <td>2</td>\n",
              "      <td>880606923</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>166</td>\n",
              "      <td>346</td>\n",
              "      <td>1</td>\n",
              "      <td>886397596</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   userID  itemID  rating  timestamp  popularity\n",
              "0     196     242       3  881250949         0.0\n",
              "1     186     302       3  891717742         0.0\n",
              "2      22     377       1  878887116         0.0\n",
              "3     244      51       2  880606923         0.0\n",
              "4     166     346       1  886397596         0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xDu_THj3zdtp",
        "colab": {}
      },
      "source": [
        "average_user_rating_recsys = BaseLineRecSys('useraverage')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gQWmspQGzdtr",
        "outputId": "9bfda316-035f-466c-c532-765418c72271",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "average_user_rating_recsys.predict_all(rating_df, num_users, num_items)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n",
            "calculated 800 users\n",
            "calculated 900 users\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yl8uLyIqzdty",
        "outputId": "3e84904a-9038-4278-8260-2764a9d8d324",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        }
      },
      "source": [
        "average_user_rating_recsys.getModel()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.        , 0.        , ..., 3.61029412, 3.61029412,\n",
              "        3.61029412],\n",
              "       [0.        , 3.70967742, 3.70967742, ..., 3.70967742, 3.70967742,\n",
              "        3.70967742],\n",
              "       [2.7962963 , 2.7962963 , 2.7962963 , ..., 2.7962963 , 2.7962963 ,\n",
              "        2.7962963 ],\n",
              "       ...,\n",
              "       [0.        , 4.04545455, 4.04545455, ..., 4.04545455, 4.04545455,\n",
              "        4.04545455],\n",
              "       [4.26582278, 4.26582278, 4.26582278, ..., 4.26582278, 4.26582278,\n",
              "        4.26582278],\n",
              "       [3.41071429, 0.        , 3.41071429, ..., 3.41071429, 3.41071429,\n",
              "        3.41071429]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "arSCkkxozdt4",
        "outputId": "2a6ec424-801d-4a97-f137-e09464e57c67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        }
      },
      "source": [
        "average_user_rating_recsys.evaluate_test(rating_df,copy=True).head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100000it [01:25, 1167.24it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userID</th>\n",
              "      <th>itemID</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>useraverage</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>196</td>\n",
              "      <td>242</td>\n",
              "      <td>3</td>\n",
              "      <td>881250949</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>186</td>\n",
              "      <td>302</td>\n",
              "      <td>3</td>\n",
              "      <td>891717742</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>22</td>\n",
              "      <td>377</td>\n",
              "      <td>1</td>\n",
              "      <td>878887116</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>244</td>\n",
              "      <td>51</td>\n",
              "      <td>2</td>\n",
              "      <td>880606923</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>166</td>\n",
              "      <td>346</td>\n",
              "      <td>1</td>\n",
              "      <td>886397596</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   userID  itemID  rating  timestamp  useraverage\n",
              "0     196     242       3  881250949          0.0\n",
              "1     186     302       3  891717742          0.0\n",
              "2      22     377       1  878887116          0.0\n",
              "3     244      51       2  880606923          0.0\n",
              "4     166     346       1  886397596          0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "u_RlOlrIzdt7"
      },
      "source": [
        "## Q2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "I4zY0XYDzdt7"
      },
      "source": [
        "### (a)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GEQ_IkS3zdt8",
        "colab": {}
      },
      "source": [
        "class SimBasedRecSys(object):\n",
        "\n",
        "    def __init__(self, base, method, processor=dataPreprocessor):\n",
        "        \"\"\"\n",
        "            base: string. From ['user', 'item']. User-based Similarity or Item-based\n",
        "            method: string. From ['cosine', 'euclidean', 'somethingelse']\n",
        "            processor: function name. dataPreprocessor by default\n",
        "        \"\"\"\n",
        "        self.base = base\n",
        "        self.method_name = method\n",
        "        self.method = self._getMethod(self.method_name)\n",
        "        self.processor = processor\n",
        "        self.pred_column_name = self.base+'-'+self.method_name\n",
        "    \n",
        "    def _getMethod(self, method_name):\n",
        "        \"\"\"\n",
        "            Don't change this\n",
        "        \"\"\"\n",
        "        switcher = {\n",
        "            'cosine': self.cosine,\n",
        "            'euclidean': self.euclidean,\n",
        "            'somethingelse': self.somethingelse,\n",
        "        }\n",
        "        \n",
        "        return switcher[method_name]\n",
        "    \n",
        "    @staticmethod\n",
        "    def cosine(matrix):\n",
        "        \"\"\"\n",
        "            cosine similarity\n",
        "        \"\"\"\n",
        "        similarity_matrix = 1 - pairwise_distances(matrix, metric='cosine')\n",
        "        return similarity_matrix\n",
        "    \n",
        "    @staticmethod\n",
        "    def euclidean(matrix):\n",
        "        \"\"\"\n",
        "            euclidean similarity\n",
        "        \"\"\"\n",
        "        converter = np.vectorize(lambda x: 1/((x+1))) #between [0,1]\n",
        "        similarity_matrix = converter(pairwise_distances(matrix))\n",
        "        \n",
        "        return similarity_matrix\n",
        "    \n",
        "    @staticmethod\n",
        "    def somethingelse(matrix):\n",
        "        \"\"\"\n",
        "            manhattan? or super-natural intuition similarity\n",
        "        \"\"\"\n",
        "        converter = np.vectorize(lambda x: 1/((x+1)))\n",
        "        similarity_matrix = converter(pairwise_distances(matrix, \n",
        "                                                         metric='manhattan'))\n",
        "\n",
        "        return similarity_matrix\n",
        "        \n",
        "    def predict_all(self, train_df, num_users, num_items):\n",
        "        \"\"\"\n",
        "            INPUT: \n",
        "                data: pandas DataFrame. columns=['userID', 'itemID', 'rating'...]\n",
        "                num_row: scalar. number of users\n",
        "                num_col: scalar. number of items\n",
        "            OUTPUT:\n",
        "                no return... this method assigns the result to self.model\n",
        "            \n",
        "            NOTES:\n",
        "                self.__model should contain predictions for *all* user and items\n",
        "                (don't worry about predicting for observed (user,item) pairs,\n",
        "                 since we won't be using these predictions in the evaluation)\n",
        "                (see code in for an efficient vectorized example)\n",
        "        \"\"\"\n",
        "        train_matrix = self.processor(train_df, num_users, num_items)\n",
        "        \n",
        "        if self.base == 'user':   \n",
        "            similarity = self.method(train_matrix)        \n",
        "            # Initialize the predicted rating matrix with zeros\n",
        "            temp_matrix = np.zeros(train_matrix.shape)\n",
        "            temp_matrix[train_matrix.nonzero()] = 1\n",
        "            \n",
        "            # UxI: UxU mul UxI\n",
        "            normalizer = np.matmul(similarity, temp_matrix) #number of users*number of items\n",
        "            #print(normalizer)\n",
        "            normalizer[normalizer == 0] = 1e-5 #10**-5\n",
        "            #what's the dimension of np.matmul(uu_similarity, trainSet)\n",
        "            \n",
        "            #why do we need a normalizer? 分子是rating*simi的和，我们只需要rating，simi加多了，所以要除掉\n",
        "            predictionMatrix = np.matmul(similarity, train_matrix)/normalizer \n",
        "            #predictionMatrix[temp_matrix.nonzero()] = 0\n",
        "            #Cold start\n",
        "            # if no one has rated this item before, use user average  \n",
        "            #numberof users*1\n",
        "            #\u0003\u0003不会整除0\n",
        "            useraverage = np.sum(train_matrix, axis=1)/(np.sum(temp_matrix, axis=1) + 1e-5) #axis=1 tuple横着加 sum of user rating/#user\n",
        "            columns = np.sum(predictionMatrix, axis=0) #sum of ratings for each item #1*number of items\n",
        "            #print(columns.shape) \n",
        "            #把所有0update成average\n",
        "            predictionMatrix[:, columns==0] = predictionMatrix[:, columns==0] + np.expand_dims(useraverage, axis=1)\n",
        "                                             #columns这个matrix数列里数字是0的index对应的predictionMatrix\n",
        "            self.__model = predictionMatrix\n",
        "        \n",
        "    \n",
        "        elif self.base == 'item':\n",
        "            train_matrix = train_matrix.T\n",
        "            similarity = self.method(train_matrix)  #similarity of items\n",
        "             # Initialize the predicted rating matrix with zeros\n",
        "            temp_matrix = np.zeros(train_matrix.shape)\n",
        "            temp_matrix[train_matrix.nonzero()] = 1\n",
        "            \n",
        "            # UxI: UxU mul UxI\n",
        "            normalizer = np.matmul(similarity, temp_matrix) #number of users*number of items\n",
        "            #print(normalizer)\n",
        "            normalizer[normalizer == 0] = 1e-5 #10**-5\n",
        "            #what's the dimension of np.matmul(uu_similarity, trainSet)\n",
        "    \n",
        "            predictionMatrix = np.matmul(similarity, train_matrix)/normalizer #why do we need a normalizer?\n",
        "            #predictionMatrix[temp_matrix.nonzero()] = 0\n",
        "            #Cold start\n",
        "            # if no one has rated this item before, use user average  \n",
        "            #numberof users*1\n",
        "            itemaverage = np.sum(train_matrix, axis=1)/(np.sum(temp_matrix, axis=1) + 1e-5) #axis=1 tuple横着加 sum of user rating/#user\n",
        "            columns = np.sum(predictionMatrix, axis=0) #sum of ratings for each item #1*number of items\n",
        "            #print(columns.shape) \n",
        "            #把所有0update成average\n",
        "            predictionMatrix[:, columns==0] = predictionMatrix[:, columns==0] + np.expand_dims(itemaverage, axis=1)\n",
        "                                             #columns这个matrix数列里数字是0的index对应的predictionMatrix\n",
        "\n",
        "            self.__model = predictionMatrix.T #return the prediction matrix\n",
        "\n",
        "\n",
        "        else:\n",
        "            print('No other option available')\n",
        "        \n",
        "    def evaluate_test(self, test_df, copy=False):\n",
        "        \"\"\"\n",
        "            INPUT:\n",
        "                data: pandas DataFrame. columns=['userID', 'itemID', 'rating'...]\n",
        "            OUTPUT:\n",
        "                predictions:  pandas DataFrame. \n",
        "                              columns=['userID', 'itemID', 'rating', 'base-method'...]\n",
        "                              \n",
        "            NOTE: 1. data can have more columns, but your function should ignore \n",
        "                  additional columns.\n",
        "                  2. 'base-method' depends on your 'base' and 'method'. For example,\n",
        "                  if base == 'user' and method == 'cosine', \n",
        "                  then base-method == 'user-cosine'\n",
        "                  3. your predictions go to 'base-method' column\n",
        "        \"\"\"\n",
        "        if copy:\n",
        "            prediction = test_df.copy()\n",
        "        else:\n",
        "            prediction = test_df\n",
        "        prediction[self.pred_column_name] = np.nan\n",
        "        \n",
        "        for (index, \n",
        "             userID, \n",
        "             itemID) in tqdm(prediction[['userID','itemID']].itertuples()):\n",
        "            prediction.loc[index, self.pred_column_name] = self.__model[userID-1, itemID-1]\n",
        "    \n",
        "        return prediction\n",
        "    \n",
        "    def getModel(self):\n",
        "        \"\"\"\n",
        "            return predicted user-item matrix\n",
        "        \"\"\"\n",
        "        return self.__model\n",
        "    \n",
        "    def getPredColName(self):\n",
        "        \"\"\"\n",
        "            return prediction column name\n",
        "        \"\"\"\n",
        "        return self.pred_column_name\n",
        "    \n",
        "    def reset(self):\n",
        "        \"\"\"\n",
        "            reuse the instance of the class by removing model\n",
        "        \"\"\"\n",
        "        try:\n",
        "            self.model = None\n",
        "        except:\n",
        "            print(\"You do not have model..\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krKdk871h_tw",
        "colab_type": "code",
        "outputId": "33d75983-d623-43a0-bf11-6bd1e6917841",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "a = np.array([2,3,4,5])+3\n",
        "a"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 6, 7, 8])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RROHVWRpzduA",
        "outputId": "aa021cae-0ca1-47d7-8853-ca072d78fa77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "# Examples of how to call similarity functions.\n",
        "I = np.eye(3) #I dimension\n",
        "SimBasedRecSys.cosine(I)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZQ5BkzGPzduC",
        "outputId": "c8772dd0-1af8-4998-925b-96d7bbd2bc54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "SimBasedRecSys.euclidean(I)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.        , 0.41421356, 0.41421356],\n",
              "       [0.41421356, 1.        , 0.41421356],\n",
              "       [0.41421356, 0.41421356, 1.        ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_O-_xcIPpn3_",
        "colab_type": "code",
        "outputId": "d0b25200-8145-4055-95dc-0514c78ddecb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "a = ([0,2,1], [0,1,0])\n",
        "columns = np.sum(a, axis=0) \n",
        "b = np.matrix(a)\n",
        "print(columns)\n",
        "b[:, columns == 0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 3 1]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "matrix([[0],\n",
              "        [0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2V-L-T-PzduF",
        "outputId": "49852b47-62ef-478f-d3f0-50b965cdc00c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "SimBasedRecSys.somethingelse(I)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.        , 0.33333333, 0.33333333],\n",
              "       [0.33333333, 1.        , 0.33333333],\n",
              "       [0.33333333, 0.33333333, 1.        ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7HplD-SiAuDL",
        "colab_type": "text"
      },
      "source": [
        "Cosine similarity works better because it uses angle instead of distance. The angle between the three points is zero whereas the distance is not. Even though user1 has nothing in common with user2 for item_i, their euclidean distance is still not zero. Further more, the euclidean distance is sensitive to similar vectors of different length. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "USPsbXpnzduH"
      },
      "source": [
        "### (b) \n",
        "I choose Manhanttan distance as the thrid metric because it is less sensitive to distance than euclidean."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qDrJogepzduL"
      },
      "source": [
        "## Q3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1Ju9mZE9zduM"
      },
      "source": [
        "### (a)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zAaSIC3BzduM",
        "colab": {}
      },
      "source": [
        "user_cosine_recsys = SimBasedRecSys('user','cosine')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dBGVr2_JzduQ",
        "colab": {}
      },
      "source": [
        "user_cosine_recsys.predict_all(rating_df, num_users, num_items)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "isW4B7nfzduW",
        "outputId": "42dc3750-941d-4c39-e748-4183866fa151",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        }
      },
      "source": [
        "user_cosine_recsys.getModel()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3.89911175, 3.19022667, 3.0261129 , ..., 2.        , 3.        ,\n",
              "        3.        ],\n",
              "       [3.84034456, 3.17139889, 2.92626717, ..., 2.        , 3.        ,\n",
              "        3.        ],\n",
              "       [3.87104065, 3.12823798, 3.03250708, ..., 2.        , 3.        ,\n",
              "        3.        ],\n",
              "       ...,\n",
              "       [3.90754645, 3.20227238, 3.05776201, ..., 2.        , 3.        ,\n",
              "        3.        ],\n",
              "       [3.91100649, 3.21591021, 2.98854017, ..., 2.        , 3.        ,\n",
              "        3.        ],\n",
              "       [3.91593122, 3.24268207, 3.08255897, ..., 0.        , 3.        ,\n",
              "        3.        ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wdxjAZJrzdud",
        "outputId": "5a569c3e-7cb4-443a-918d-729bd595e105",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "rating_df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userID</th>\n",
              "      <th>itemID</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>196</td>\n",
              "      <td>242</td>\n",
              "      <td>3</td>\n",
              "      <td>881250949</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>186</td>\n",
              "      <td>302</td>\n",
              "      <td>3</td>\n",
              "      <td>891717742</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>22</td>\n",
              "      <td>377</td>\n",
              "      <td>1</td>\n",
              "      <td>878887116</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>244</td>\n",
              "      <td>51</td>\n",
              "      <td>2</td>\n",
              "      <td>880606923</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>166</td>\n",
              "      <td>346</td>\n",
              "      <td>1</td>\n",
              "      <td>886397596</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   userID  itemID  rating  timestamp\n",
              "0     196     242       3  881250949\n",
              "1     186     302       3  891717742\n",
              "2      22     377       1  878887116\n",
              "3     244      51       2  880606923\n",
              "4     166     346       1  886397596"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yc2PgKylzdug",
        "scrolled": true,
        "outputId": "4e648de5-ed7c-4c34-bcef-004acff6b9d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "user_cosine_recsys.evaluate_test(rating_df,copy=True).head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "74254it [01:08, 1099.64it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pZdTvp_szduk"
      },
      "source": [
        "### (b)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "k-BnXbsLzdul",
        "colab": {}
      },
      "source": [
        "class CrossValidation(object):\n",
        "    def __init__(self, metric, data_path=MOVIELENS_DIR):\n",
        "        \"\"\"\n",
        "            INPUT:\n",
        "                metric: string. from['RMSE','P@K','R@K']\n",
        "        \"\"\"\n",
        "        self.folds = self._getData(MOVIELENS_DIR)\n",
        "        self.metric_name = metric\n",
        "        self.metric = self._getMetric(self.metric_name)\n",
        "        \n",
        "    def _getMetric(self, metric_name):\n",
        "        \"\"\"\n",
        "            Don't change this\n",
        "        \"\"\"\n",
        "        switcher = {\n",
        "            'RMSE': self.rmse,\n",
        "            'P@K': self.patk,\n",
        "            'R@K': self.ratk,\n",
        "        }\n",
        "        \n",
        "        return switcher[metric_name]\n",
        "    \n",
        "    @staticmethod\n",
        "    def rmse(data, k, num_users, num_items, pred, true='rating'):\n",
        "        \"\"\"\n",
        "            data: pandas DataFrame. \n",
        "            pred: string. Column name that corresponding to the prediction\n",
        "            true: string. Column name that corresponding to the true rating\n",
        "        \"\"\"\n",
        "        return sqrt(mean_squared_error(data[pred], data[true]))\n",
        "    \n",
        "    # Precision at k\n",
        "    def patk(self, data, k, num_users, num_items, pred, true='rating'):\n",
        "        \"\"\"\n",
        "            data: pandas DataFrame. \n",
        "            k: top-k items retrived\n",
        "            pred: string. Column name that corresponding to the prediction\n",
        "            true: string. Column name that corresponding to the true rating\n",
        "        \"\"\"\n",
        "        prediction = self.getMatrix(data, num_users, num_items, pred)\n",
        "        testSet =  self.getMatrix(data, num_users, num_items, true)\n",
        "    \n",
        "        # Initialize sum and count vars for average calculation\n",
        "        sumPrecisions = 0\n",
        "        countPrecisions = 0\n",
        "\n",
        "        # Define function for converting 1-5 rating to 0/1 (like / don't like)\n",
        "        vf = np.vectorize(lambda x: 1 if x >= 4 else 0)\n",
        "\n",
        "        for userID in range(num_users):\n",
        "            # Pick top K based on predicted rating\n",
        "            userVector = prediction[userID,:]\n",
        "            topK = nlargest(k, range(len(userVector)), userVector.take)\n",
        "\n",
        "            # Convert test set ratings to like / don't like\n",
        "            userTestVector = vf(testSet[userID,:]).nonzero()[0]\n",
        "\n",
        "            # Calculate precision\n",
        "            precision = float(len([item for item in topK if item in userTestVector]))/len(topK)\n",
        "\n",
        "            # Update sum and count\n",
        "            sumPrecisions += precision\n",
        "            countPrecisions += 1\n",
        "\n",
        "        # Return average P@k\n",
        "        return float(sumPrecisions)/countPrecisions\n",
        "    \n",
        "    # Recall at k\n",
        "    def ratk(self, data, k, num_users, num_items, pred, true='rating'):\n",
        "        \"\"\"\n",
        "            data: pandas DataFrame. \n",
        "            k: top-k items relevant\n",
        "            pred: string. Column name that corresponding to the prediction\n",
        "            true: string. Column name that corresponding to the true rating\n",
        "        \"\"\"\n",
        "        prediction = self.getMatrix(data, num_users, num_items, pred)\n",
        "        testSet =  self.getMatrix(data, num_users, num_items, true)\n",
        "        # Initialize sum and count vars for average calculation\n",
        "        sumRecalls = 0\n",
        "        countRecalls = 0\n",
        "\n",
        "        # Define function for converting 1-5 rating to 0/1 (like / don't like)\n",
        "        vf = np.vectorize(lambda x: 1 if x >= 4 else 0)\n",
        "\n",
        "        for userID in range(num_users):\n",
        "            # Pick top K based on predicted rating\n",
        "            userVector = prediction[userID,:]\n",
        "            topK = nlargest(k, range(len(userVector)), userVector.take)\n",
        "\n",
        "            # Convert test set ratings to like / don't like\n",
        "            userTestVector = vf(testSet[userID,:]).nonzero()[0]\n",
        "\n",
        "            # Ignore user if has no ratings in the test set\n",
        "            if (len(userTestVector) == 0):\n",
        "                continue\n",
        "\n",
        "            # Calculate recall\n",
        "            recall = float(len([item for item in topK if item in userTestVector]))/len(userTestVector)\n",
        "\n",
        "            # Update sum and count\n",
        "            sumRecalls += recall\n",
        "            countRecalls += 1\n",
        "\n",
        "        # Return average R@k\n",
        "        return float(sumRecalls)/countRecalls\n",
        "    \n",
        "    @staticmethod\n",
        "    def getMatrix(rating_df, num_users, num_items, column_name): #column_name: true, pred\n",
        "        matrix = np.zeros((num_users, num_items))\n",
        "    \n",
        "        for (index, userID, itemID, value) in rating_df[['userID','itemID', column_name]].itertuples():\n",
        "            matrix[userID-1, itemID-1] = value\n",
        "            \n",
        "        return matrix\n",
        "    \n",
        "    @staticmethod\n",
        "    def _getData(data_path):\n",
        "        \"\"\"\n",
        "            Don't change this function\n",
        "        \"\"\"\n",
        "        folds = []\n",
        "        data_types = ['u{0}.base','u{0}.test']\n",
        "        for i in range(1,6):\n",
        "            train_set = getData(data_path, data_types[0].format(i))\n",
        "            test_set = getData(data_path, data_types[1].format(i))\n",
        "            folds.append([train_set, test_set])\n",
        "        return folds\n",
        "    \n",
        "    def run(self, algorithms, num_users, num_items, k=1):\n",
        "        \"\"\"\n",
        "            5-fold cross-validation\n",
        "            algorithms: list. a list of algorithms. \n",
        "                        eg: [user_cosine_recsys, item_euclidean_recsys]\n",
        "        \"\"\"\n",
        "        \n",
        "        scores = {}\n",
        "        for algorithm in algorithms:\n",
        "            print('Processing algorithm {0}'.format(algorithm.getPredColName()))\n",
        "            fold_scores = []\n",
        "            for fold in self.folds:\n",
        "                algorithm.reset()\n",
        "                algorithm.predict_all(fold[0], num_users, num_items)\n",
        "                prediction = algorithm.evaluate_test(fold[1])\n",
        "                pred_col = algorithm.getPredColName()\n",
        "                fold_scores.append(self.metric(prediction, k, num_users, num_items, pred_col))\n",
        "                \n",
        "            mean = np.mean(fold_scores)\n",
        "            ci_low, ci_high = stats.t.interval(0.95, len(fold_scores)-1, loc=mean, scale=stats.sem(fold_scores))\n",
        "            scores[algorithm.getPredColName()] = [fold_scores, mean, ci_low, ci_high]\n",
        "            \n",
        "        results = scores    \n",
        "    \n",
        "        return results\n",
        "            "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eJKyb9l-zdun",
        "colab": {}
      },
      "source": [
        "# How to use CrossValidation Class?\n",
        "user_cosine_recsys = SimBasedRecSys('user','cosine')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CU3rZPtnzdus",
        "colab": {}
      },
      "source": [
        "# 1. gather your algorithms in previous steps.\n",
        "algorithm_instances_1 = [popularity_recsys, \n",
        "                       average_user_rating_recsys, \n",
        "                       user_cosine_recsys]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xf-m7d5Dzdux",
        "colab": {}
      },
      "source": [
        "# 2. Instantiate a CrossValidation instance and assign the measurement that you want to use\n",
        "# RMSE, P@K, R@K\n",
        "# Precision at K in this example\n",
        "cv_rmse_1 = CrossValidation('RMSE')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XqcihyZdzduz",
        "colab": {}
      },
      "source": [
        "# 3. Run CV by giving:\n",
        "#    1> algorithms just gathered\n",
        "#    2> number of users in the full dataset\n",
        "#    3> number of items in the full dataset\n",
        "#    4> precision or recall at K need a K value, so k=5 means precision at 5 in this example\n",
        "# Results include independent results from 5 folds, their mean, and confidence interval.\n",
        "cv_rmse_1.run(algorithm_instances_1, num_users, num_items,k=5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xt4ER5jD0Vi2",
        "colab_type": "code",
        "outputId": "706d4adf-c045-46b3-9891-e17a69e9f26c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "item_cosine_recsys = SimBasedRecSys('item','cosine')\n",
        "algorithm_instances_item_1 = [popularity_recsys, \n",
        "                       average_user_rating_recsys, \n",
        "                       item_cosine_recsys]\n",
        "\n",
        "cv_rmse_1 = CrossValidation('RMSE')\n",
        "cv_rmse_1.run(algorithm_instances_item_1, num_users, num_items,k=5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing algorithm popularity\n",
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n",
            "calculated 800 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:09, 2031.27it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n",
            "calculated 800 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:09, 2014.85it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n",
            "calculated 800 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:09, 2024.93it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n",
            "calculated 800 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:09, 2061.12it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n",
            "calculated 800 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:09, 2031.36it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Processing algorithm useraverage\n",
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n",
            "calculated 800 users\n",
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:09, 2056.03it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n",
            "calculated 800 users\n",
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:09, 2035.22it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n",
            "calculated 800 users\n",
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:09, 2061.21it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n",
            "calculated 800 users\n",
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:09, 2069.03it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n",
            "calculated 800 users\n",
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:09, 2041.47it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Processing algorithm item-cosine\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:10, 1961.56it/s]\n",
            "20000it [00:09, 2015.20it/s]\n",
            "20000it [00:09, 2031.37it/s]\n",
            "20000it [00:09, 2036.27it/s]\n",
            "20000it [00:09, 2039.78it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'item-cosine': [[1.0377631264364244,\n",
              "   1.0207280585350078,\n",
              "   1.0101820660011798,\n",
              "   1.0136832839209695,\n",
              "   1.0180579656376574],\n",
              "  1.020082900106248,\n",
              "  1.0068242686250732,\n",
              "  1.0333415315874226],\n",
              " 'popularity': [[3.177941281084362,\n",
              "   3.1750480150769977,\n",
              "   3.147474655005899,\n",
              "   3.146164503024159,\n",
              "   3.1488360007536382],\n",
              "  3.1590928909890112,\n",
              "  3.139292746995387,\n",
              "  3.1788930349826354],\n",
              " 'useraverage': [[1.0629951276561334,\n",
              "   1.0467467492319966,\n",
              "   1.0328964562995389,\n",
              "   1.0366575971298078,\n",
              "   1.0392923504800367],\n",
              "  1.0437176561595025,\n",
              "  1.0289303496379316,\n",
              "  1.0585049626810734]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddUF3F2KnEHJ",
        "colab_type": "text"
      },
      "source": [
        "* User-user based collaborative filtering for cosine similariy has a mean of  1.017 for RSME, with 95% confidence interval between [1.009,\n",
        "  1.026]. \n",
        "* Item-item based collaborative filtering for cosine similarity has a mean of 1.020, with 95% confidence interval between [1.007, 1.033]. Item-item based performed slightly better than user-user based. \n",
        "* This is possibly because the average number of  ratings per user is more than the average number of ratings per item, in this case, Number of users: 943\n",
        "Number of items: 1682. The more number of ratings, the more approximate the prediction is."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nJCFpLY25JuY"
      },
      "source": [
        "## Q4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RMdW5aLG5OTH"
      },
      "source": [
        "### (a)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AI1hS4CP5RVP",
        "colab": {}
      },
      "source": [
        "class PMFRecSys(object):\n",
        "    def __init__(self, num_feat=10, epsilon=1, _lambda=0.1, momentum=0.8, maxepoch=20, num_batches=10, batch_size=1000):\n",
        "        \"\"\"\n",
        "            num_feat: int, number of latent features\n",
        "            epsilon: float, learning rate\n",
        "            _lambda: float, L2 regularization,\n",
        "            momentum: float, momentum of the gradient,\n",
        "            maxepoch: float, Number of epoch before stop,\n",
        "            num_batches: int, Number of batches in each epoch (for SGD optimization),\n",
        "            batch_size:Number int, of training samples used in each batches (for SGD optimization)\n",
        "            \n",
        "        \"\"\"\n",
        "        self.num_feat = num_feat  # Number of latent features,\n",
        "        self.epsilon = epsilon  # learning rate,\n",
        "        self._lambda = _lambda  # L2 regularization,\n",
        "        self.momentum = momentum  # momentum of the gradient,\n",
        "        self.maxepoch = maxepoch  # Number of epoch before stop,\n",
        "        self.num_batches = num_batches  # Number of batches in each epoch (for SGD optimization),\n",
        "        self.batch_size = batch_size  # Number of training samples used in each batches (for SGD optimization)\n",
        "        self.test = False\n",
        "        self.w_Item = None  # Item feature vectors\n",
        "        self.w_User = None  # User feature vectors\n",
        "        \n",
        "        self.rmse_train = []\n",
        "        self.rmse_test = []\n",
        "        self.pred_column_name='PMF'\n",
        "\n",
        "    def predict_all(self, train_vec, num_user, num_item):\n",
        "        \"\"\"\n",
        "            INPUT: \n",
        "                data: pandas DataFrame. columns=['userID', 'itemID', 'rating'...]\n",
        "                num_user: scalar. number of users\n",
        "                num_item: scalar. number of items\n",
        "            OUTPUT:\n",
        "                no return... this method update w_User and w_Item\n",
        "            \n",
        "            NOTES:\n",
        "                self.W_Item and self.W_User are use to do the final predition for a user\n",
        "                \n",
        "        \"\"\"\n",
        "        # select 'userID', 'itemID', 'rating only\n",
        "        train_vec = train_vec.iloc[:, :3].values #user, item, rating\n",
        "        if self.test: #if split train into train' and validate\n",
        "          train_vec, val_vec = train_test_split(train_vec)\n",
        "          pairs_val = val_vec.shape[0] #number of data points in the validate set \n",
        "          self.mean_rating_test = np.mean(val_vec[:, 2])\n",
        "        self.mean_rating_train = np.mean(train_vec[:, 2])  # avg rating\n",
        "        pairs_train = train_vec.shape[0]  # num of rating\n",
        "        \n",
        "\n",
        "        # to avoid out of bound, why?\n",
        "        num_user += 1  \n",
        "        num_item += 1  \n",
        "        # initialize\n",
        "        self.epoch = 0\n",
        "        \n",
        "        ########### your code goes here ###########\n",
        "    \n",
        "        self.w_Item = sqrt(0.1) * np.random.randn(num_item,self.num_feat)\n",
        "        self.w_User = sqrt(0.1) * np.random.randn(num_user,self.num_feat) #sigma * np.random.randn(...) + mu\n",
        "    \n",
        "        ###########         end         ###########  \n",
        "\n",
        "        self.w_Item_inc = np.zeros((num_item, self.num_feat))  # accumulate the gradient\n",
        "        self.w_User_inc = np.zeros((num_user, self.num_feat))  # accumulate the gradient\n",
        "        while self.epoch < self.maxepoch: \n",
        "            self.epoch += 1\n",
        "\n",
        "            # Shuffle training truples\n",
        "            shuffled_order = np.arange(train_vec.shape[0])  # num of rating, array([0,1,2,...])\n",
        "            np.random.shuffle(shuffled_order)  #shuffled array([34,2,54,..])\n",
        "\n",
        "            # Batch update\n",
        "            for batch in range(self.num_batches): \n",
        "                # print \"epoch %d batch %d\" % (self.epoch, batch+1)\n",
        "\n",
        "                test = np.arange(self.batch_size * batch, self.batch_size * (batch + 1)) #batch = 0,1,2,3 是几乘几 [30,31,32,..,60] if batch = 1, size = 30\n",
        "                batch_idx = np.mod(test, shuffled_order.shape[0])  # get the real data index #return remainder (nominator, denominator)\n",
        "                #([30,31,32,..,60], number of rating)\n",
        "\n",
        "                batch_UserID = np.array(train_vec[shuffled_order[batch_idx], 0], dtype='int32') #user那列shuffle后的index对应的rating\n",
        "                batch_ItemID = np.array(train_vec[shuffled_order[batch_idx], 1], dtype='int32') #item那列shuffle后的index\n",
        "\n",
        "                # Compute Compute mean rating subtracted rating  \n",
        "                ########### your code goes here ###########\n",
        "               \n",
        "                pred_out = np.sum(np.multiply(self.w_User[batch_UserID, :], self.w_Item[batch_ItemID, :]), axis=1)\n",
        "                #size (batch_size, )\n",
        "            \n",
        "                ###########         end         ########### \n",
        "\n",
        "                rawErr = pred_out + self.mean_rating_train - train_vec[shuffled_order[batch_idx], 2]\n",
        "\n",
        "                # Compute gradients\n",
        "                Ix_User = 2 * np.multiply(rawErr[:, np.newaxis], self.w_Item[batch_ItemID, :]) \\\n",
        "                       + self._lambda * self.w_User[batch_UserID, :] #_lambda:regularization \n",
        "                Ix_Item = 2 * np.multiply(rawErr[:, np.newaxis], self.w_User[batch_UserID, :]) \\\n",
        "                       + self._lambda * (self.w_Item[batch_ItemID, :])  # np.newaxis :increase the dimension\n",
        "\n",
        "                dw_Item = np.zeros((num_item, self.num_feat)) # accumulate the gradient\n",
        "                dw_User = np.zeros((num_user, self.num_feat))\n",
        "\n",
        "                # loop to aggreate the gradients of the same element\n",
        "                for i in range(self.batch_size):\n",
        "                    dw_Item[batch_ItemID[i], :] += Ix_Item[i, :]\n",
        "                    dw_User[batch_UserID[i], :] += Ix_User[i, :]\n",
        "\n",
        "                # Update with momentum\n",
        "                self.w_Item_inc = self.momentum * self.w_Item_inc + self.epsilon * dw_Item / self.batch_size\n",
        "                self.w_User_inc = self.momentum * self.w_User_inc + self.epsilon * dw_User / self.batch_size\n",
        "\n",
        "                self.w_Item = self.w_Item - self.w_Item_inc \n",
        "                self.w_User = self.w_User - self.w_User_inc\n",
        "\n",
        "                # Compute Compute mean rating subtracted rating \n",
        "                if batch == self.num_batches - 1:\n",
        "                    train_user_idx = np.array(train_vec[:, 0], dtype='int32')\n",
        "                    train_item_idx = np.array(train_vec[:, 1], dtype='int32')\n",
        "                    ########### your code goes here ###########\n",
        "            \n",
        "                    pred_out = np.sum(np.multiply(self.w_User[train_user_idx, :], self.w_Item[train_item_idx, :]), axis=1)\n",
        "            \n",
        "            \n",
        "                    ###########         end         ########### \n",
        "                    rawErr = pred_out + self.mean_rating_train - train_vec[:, 2] \n",
        "                    obj = np.linalg.norm(rawErr) ** 2 \\\n",
        "                          + 0.5 * self._lambda * (np.linalg.norm(self.w_User) ** 2 + np.linalg.norm(self.w_Item) ** 2)\n",
        "\n",
        "                    self.rmse_train.append(np.sqrt(obj / pairs_train))\n",
        "\n",
        "                # Compute validation error\n",
        "                if batch == self.num_batches - 1 and self.test:\n",
        "                    val_user_idx = np.array(val_vec[:, 0], dtype='int32')\n",
        "                    val_item_idx = np.array(val_vec[:, 1], dtype='int32')\n",
        "                    ########### your code goes here ###########\n",
        "            \n",
        "                    pred_out = np.sum(np.multiply(self.w_User[val_user_idx, :], self.w_Item[val_item_idx, :]), axis=1)\n",
        "            \n",
        "            \n",
        "                    ###########         end         ########### \n",
        "                    rawErr = pred_out + self.mean_rating_test - val_vec[:, 2]\n",
        "                    self.rmse_test.append(np.linalg.norm(rawErr) / np.sqrt(pairs_val))\n",
        "\n",
        "\n",
        "        \n",
        "\n",
        "        \n",
        "    def evaluate_test(self, test_df, copy=False):\n",
        "        \"\"\"\n",
        "            INPUT:\n",
        "                data: pandas DataFrame. columns=['userID', 'itemID', 'rating'...]\n",
        "            OUTPUT:\n",
        "                predictions:  pandas DataFrame. \n",
        "                              columns=['userID', 'itemID', 'rating', 'base-method'...]\n",
        "                              \n",
        "        \"\"\"\n",
        "        if copy:\n",
        "            prediction = pd.DataFrame(test_df.copy(), columns=['userID', 'itemID', 'rating'])\n",
        "        else:\n",
        "            prediction = pd.DataFrame(test_df, columns=['userID', 'itemID', 'rating'])\n",
        "        prediction[self.pred_column_name] = np.nan\n",
        "        \n",
        "        for (index, \n",
        "             userID, \n",
        "             itemID) in tqdm(prediction[['userID','itemID']].itertuples()):\n",
        "            prediction.loc[index, self.pred_column_name] = (np.dot(self.w_Item, self.w_User[int(userID), :]) + self.mean_rating_train)[int(itemID)]\n",
        "    \n",
        "        return prediction\n",
        "    \n",
        "    def plot_error(self):\n",
        "      if self.test:\n",
        "        plt.plot(range(pmf.maxepoch), pmf.rmse_test, marker='v', label='Test Data')\n",
        "      plt.plot(range(pmf.maxepoch), pmf.rmse_train, marker='o', label='Training Data')\n",
        "      plt.title('The MovieLens Dataset Learning Curve')\n",
        "      plt.xlabel('Number of Epochs')\n",
        "      plt.ylabel('RMSE')\n",
        "      plt.legend()\n",
        "      plt.grid()\n",
        "      plt.show()\n",
        "          \n",
        "    def getPredColName(self):\n",
        "        \"\"\"\n",
        "            return prediction column name\n",
        "        \"\"\"\n",
        "        return self.pred_column_name\n",
        "    \n",
        "    def reset(self):\n",
        "        \"\"\"\n",
        "            reuse the instance of the class by removing model\n",
        "        \"\"\"\n",
        "        try:\n",
        "            self.w_Item = None \n",
        "            self.w_User = None \n",
        "        except:\n",
        "            print(\"You do not have w_Item, w_User\")\n",
        "\n",
        "    def set_params(self, parameters):\n",
        "        if isinstance(parameters, dict):\n",
        "            self.num_feat = parameters.get(\"num_feat\", 10)\n",
        "            self.epsilon = parameters.get(\"epsilon\", 1)\n",
        "            self._lambda = parameters.get(\"_lambda\", 0.1)\n",
        "            self.momentum = parameters.get(\"momentum\", 0.8)\n",
        "            self.maxepoch = parameters.get(\"maxepoch\", 20)\n",
        "            self.num_batches = parameters.get(\"num_batches\", 10)\n",
        "            self.batch_size = parameters.get(\"batch_size\", 1000)\n",
        "            self.test = parameters.get(\"test_mode\", False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ce7wlxycY76k",
        "colab": {}
      },
      "source": [
        "pmf = PMFRecSys()\n",
        "pmf.set_params({\"num_feat\": 10, \"epsilon\": 1, \"_lambda\": 0.1, \"momentum\": 0.8, \"maxepoch\": 100, \"num_batches\": 100,\n",
        "                \"batch_size\": 1000, 'test_mode':True})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "p56cFny7Y_Z_",
        "outputId": "e8e3d43c-8ebc-4ca4-894a-8ae39d06b88b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "pmf.predict_all(rating_df, num_users, num_items)\n",
        "pmf.plot_error()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-tkSLeDqzdu1"
      },
      "source": [
        "## Q5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "00OSiRl9zdu2"
      },
      "source": [
        "### (a)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YS4qfLOAzdu2",
        "colab": {}
      },
      "source": [
        "pmf = PMFRecSys()\n",
        "pmf.set_params({\"num_feat\": 10, \"epsilon\": 1, \"_lambda\": 0.1, \"momentum\": 0.8, \"maxepoch\": 15, \"num_batches\": 100,\n",
        "                \"batch_size\": 1000, 'test_mode':True})\n",
        "#algorithm_instances_item = [popularity_recsys, \n",
        "                      #  average_user_rating_recsys, \n",
        "                      #  user_cosine_recsys]  \n",
        "algorithm_instances_all = [popularity_recsys, \n",
        "                           average_user_rating_recsys, \n",
        "                           user_cosine_recsys,\n",
        "                           item_cosine_recsys,\n",
        "                           pmf]\n",
        "\n",
        "cv_patk = CrossValidation('P@K')\n",
        "cv_ratk = CrossValidation('R@K')\n",
        "cv_rmse = CrossValidation('RMSE')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9ECewjOPBEh",
        "colab_type": "code",
        "outputId": "26e3ce16-520d-4e0c-9d66-2bf286f9fe35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "algorithm_instances_all"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<__main__.BaseLineRecSys at 0x7f09736a4dd8>,\n",
              " <__main__.BaseLineRecSys at 0x7f09736abcf8>,\n",
              " <__main__.SimBasedRecSys at 0x7f0973688cf8>,\n",
              " <__main__.SimBasedRecSys at 0x7f096fd02390>,\n",
              " <__main__.PMFRecSys at 0x7f096fd1a828>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uuUmZH69E8jp",
        "colab_type": "code",
        "outputId": "da0e6796-59b3-44da-c425-956ae8845ce6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "result_patk = cv_patk.run(algorithm_instances_all, num_users, num_items,k=5)\n",
        "result_ratk = cv_ratk.run(algorithm_instances_all, num_users, num_items,k=5)\n",
        "result_rmse = cv_rmse.run(algorithm_instances_all, num_users, num_items,k=5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing algorithm popularity\n",
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n",
            "calculated 800 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:09, 2107.38it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n",
            "calculated 800 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:09, 2039.43it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n",
            "calculated 800 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:09, 2041.90it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n",
            "calculated 800 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:09, 2027.94it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n",
            "calculated 800 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:09, 2054.67it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Processing algorithm useraverage\n",
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n",
            "calculated 800 users\n",
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:10, 1979.85it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n",
            "calculated 800 users\n",
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:09, 2043.11it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n",
            "calculated 800 users\n",
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:09, 2037.46it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n",
            "calculated 800 users\n",
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:09, 2019.38it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n",
            "calculated 800 users\n",
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:09, 2035.10it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Processing algorithm user-cosine\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:10, 1967.07it/s]\n",
            "20000it [00:09, 2016.56it/s]\n",
            "20000it [00:09, 2079.85it/s]\n",
            "20000it [00:09, 2006.76it/s]\n",
            "20000it [00:09, 2061.07it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Processing algorithm item-cosine\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:09, 2011.76it/s]\n",
            "20000it [00:09, 2034.25it/s]\n",
            "20000it [00:09, 2037.58it/s]\n",
            "20000it [00:09, 2027.53it/s]\n",
            "20000it [00:09, 2020.97it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Processing algorithm PMF\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:17, 1159.65it/s]\n",
            "20000it [00:17, 1137.79it/s]\n",
            "20000it [00:17, 1147.89it/s]\n",
            "20000it [00:17, 1174.43it/s]\n",
            "20000it [00:16, 1184.06it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Processing algorithm popularity\n",
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n",
            "calculated 800 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:09, 2086.75it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n",
            "calculated 800 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:09, 2044.34it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n",
            "calculated 800 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:09, 2068.63it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n",
            "calculated 800 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:09, 2056.82it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n",
            "calculated 800 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:09, 2073.34it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Processing algorithm useraverage\n",
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n",
            "calculated 800 users\n",
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:09, 2074.51it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n",
            "calculated 800 users\n",
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:09, 2078.70it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n",
            "calculated 800 users\n",
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:09, 2075.27it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n",
            "calculated 800 users\n",
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:09, 2106.20it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n",
            "calculated 800 users\n",
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:09, 2038.12it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Processing algorithm user-cosine\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:09, 2053.68it/s]\n",
            "20000it [00:09, 2050.05it/s]\n",
            "20000it [00:09, 2050.18it/s]\n",
            "20000it [00:09, 2014.04it/s]\n",
            "20000it [00:09, 2054.04it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Processing algorithm item-cosine\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:09, 2072.52it/s]\n",
            "20000it [00:09, 2054.67it/s]\n",
            "20000it [00:09, 2018.60it/s]\n",
            "20000it [00:09, 2059.76it/s]\n",
            "20000it [00:09, 2066.35it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Processing algorithm PMF\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:17, 1171.18it/s]\n",
            "20000it [00:17, 1174.31it/s]\n",
            "20000it [00:16, 1178.10it/s]\n",
            "20000it [00:17, 1167.57it/s]\n",
            "20000it [00:17, 1148.22it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Processing algorithm popularity\n",
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n",
            "calculated 800 users\n",
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:09, 2048.89it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n",
            "calculated 800 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:09, 2032.45it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n",
            "calculated 800 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:09, 2046.00it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n",
            "calculated 800 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:09, 2043.21it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n",
            "calculated 800 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:09, 2064.99it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Processing algorithm useraverage\n",
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n",
            "calculated 800 users\n",
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:09, 2029.95it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n",
            "calculated 800 users\n",
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:09, 2015.85it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n",
            "calculated 800 users\n",
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:09, 2052.43it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n",
            "calculated 800 users\n",
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:09, 2021.88it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n",
            "calculated 800 users\n",
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:09, 2041.67it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Processing algorithm user-cosine\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:09, 2033.91it/s]\n",
            "20000it [00:09, 2022.18it/s]\n",
            "20000it [00:10, 1965.03it/s]\n",
            "20000it [00:09, 2003.58it/s]\n",
            "20000it [00:09, 2023.15it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Processing algorithm item-cosine\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:09, 2041.19it/s]\n",
            "20000it [00:09, 2025.76it/s]\n",
            "20000it [00:09, 2009.80it/s]\n",
            "20000it [00:09, 2043.29it/s]\n",
            "20000it [00:09, 2038.87it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Processing algorithm PMF\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:17, 1163.30it/s]\n",
            "20000it [00:17, 1167.08it/s]\n",
            "20000it [00:17, 1152.73it/s]\n",
            "20000it [00:17, 1150.51it/s]\n",
            "20000it [00:16, 1191.23it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1X50msGMSiX",
        "colab_type": "code",
        "outputId": "b821e3a3-b5d5-4d8d-fc01-8f3316154c50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        }
      },
      "source": [
        "result_patk"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'PMF': [[0.3437963944856847,\n",
              "   0.4865323435843068,\n",
              "   0.5881230116649007,\n",
              "   0.6237539766702025,\n",
              "   0.6065747613997886],\n",
              "  0.5297560975609766,\n",
              "  0.3846981873156694,\n",
              "  0.6748140078062839],\n",
              " 'item-cosine': [[0.34316012725344736,\n",
              "   0.483563096500532,\n",
              "   0.6021208907741271,\n",
              "   0.6248144220572649,\n",
              "   0.6074231177094392],\n",
              "  0.5322163308589621,\n",
              "  0.3837005215009889,\n",
              "  0.6807321402169354],\n",
              " 'popularity': [[0.36924708377518656,\n",
              "   0.4965005302226948,\n",
              "   0.6152704135737019,\n",
              "   0.6426299045599162,\n",
              "   0.6292682926829279],\n",
              "  0.5505832449628855,\n",
              "  0.40544114481568705,\n",
              "  0.6957253451100839],\n",
              " 'user-cosine': [[0.37179215270413657,\n",
              "   0.503923647932133,\n",
              "   0.621633085896077,\n",
              "   0.6483563096500541,\n",
              "   0.6335100742311777],\n",
              "  0.5558430540827157,\n",
              "  0.40959849499983714,\n",
              "  0.7020876131655943],\n",
              " 'useraverage': [[0.30604453870625714,\n",
              "   0.4305408271474029,\n",
              "   0.5321314952279973,\n",
              "   0.5520678685047737,\n",
              "   0.5474019088016986],\n",
              "  0.4736373276776259,\n",
              "  0.3419993013451059,\n",
              "  0.6052753540101459]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHFxFQS6FiPv",
        "colab_type": "code",
        "outputId": "2af46cc2-1f94-4364-ae0a-200d8d3cbf83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "print('Method\\t\\tMean\\t\\t\\tCI')\n",
        "print('Metric: Precison@K')\n",
        "for k, v in result_patk.items():\n",
        "    print('%s \\t%f\\t%f\\t%f'% (k, v[1], v[2], v[3]))\n",
        "print('\\n')\n",
        "print('Metric: Recall@K')\n",
        "for k, v in result_ratk.items():\n",
        "    print('%s \\t%f\\t%f\\t%f'% (k, v[1], v[2], v[3]))\n",
        "print('\\n')\n",
        "print('Metric: RMSE')\n",
        "for k, v in result_rmse.items():\n",
        "    print('%s \\t%f\\t%f\\t%f'% (k, v[1], v[2], v[3]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Method\t\tMean\t\t\tCI\n",
            "Metric: Precison@K\n",
            "popularity \t0.550583\t0.405441\t0.695725\n",
            "useraverage \t0.473637\t0.341999\t0.605275\n",
            "user-cosine \t0.555843\t0.409598\t0.702088\n",
            "item-cosine \t0.532216\t0.383701\t0.680732\n",
            "PMF \t0.529756\t0.384698\t0.674814\n",
            "\n",
            "\n",
            "Metric: Recall@K\n",
            "popularity \t0.484076\t0.367137\t0.601014\n",
            "useraverage \t0.441323\t0.329310\t0.553336\n",
            "user-cosine \t0.486269\t0.369447\t0.603090\n",
            "item-cosine \t0.474971\t0.353573\t0.596369\n",
            "PMF \t0.469291\t0.352541\t0.586041\n",
            "\n",
            "\n",
            "Metric: RMSE\n",
            "popularity \t3.159093\t3.139293\t3.178893\n",
            "useraverage \t1.043718\t1.028930\t1.058505\n",
            "user-cosine \t1.017354\t1.009013\t1.025695\n",
            "item-cosine \t1.020083\t1.006824\t1.033342\n",
            "PMF \t0.999062\t0.982171\t1.015954\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4ndWFEgUzdu4"
      },
      "source": [
        "### (b) \n",
        "Popularity cannot be evaluated by RMSE. The result of popularity is a rate between the number of people who liked the item and the number of the people who rated the item. It doesn't make sense to compare the test set with the actual rating with the popularity matrix.\n",
        "### (c) \n",
        "\n",
        "\n",
        "*   **User-user cosine** did the best on P@K and R@K, while **PMF** did the best on RMSE. \n",
        "*   Both **User Average** and **Popularity** are not personalized enough. Popularity rated each item that was not rated by the user by calculating the rate between the number of people who liked the item and the number of the people who rated the item. User average took the average ratings of all users but it is very unlikely that the user will rate the same.\n",
        "*   **Item-item cosine** did fairly well but the number of items is so much more than the number of users, which makes the rating for items sparse to a point where it is less predictive than user-user cosine.  \n",
        "*   **PMF** did well on RMSE because the model is optimised with gradient descent using RMSE as the metric.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wkx8GW4wzdu8"
      },
      "source": [
        "## Q6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HnLcDctYzdu9"
      },
      "source": [
        "### (a) The three movies I picked\n",
        "257|Men in Black (1997)|04-Jul-1997||http://us.imdb.com/M/title-exact?Men+in+Black+(1997)|0|1|1|0|0|1|0|0|0|0|0|0|0|0|0|1|0|0|0\n",
        "225|101 Dalmatians (1996)|27-Nov-1996||http://us.imdb.com/M/title-exact?101%20Dalmatians%20(1996)|0|0|0|0|1|1|0|0|0|0|0|0|0|0|0|0|0|0|0\n",
        "\n",
        "1129|Chungking Express (1994)|16-Feb-1996||http://us.imdb.com/M/title-exact?Chongqing%20Senlin%20(1994)|0|0|0|0|0|0|0|0|1|0|0|0|0|1|1|0|0|0|0\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "F16agjyHzdu_",
        "outputId": "b0cc4081-d9b0-4803-a050-debbfa91b538",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        }
      },
      "source": [
        "fieldsMovies = ['movieID', 'movieTitle', 'releaseDate', 'videoReleaseDate', 'IMDbURL', 'unknown', 'action', 'adventure',\n",
        "                'animation', 'childrens', 'comedy', 'crime', 'documentary', 'drama', 'fantasy', 'filmNoir', 'horror',\n",
        "                'musical', 'mystery', 'romance','sciFi', 'thriller', 'war', 'western']\n",
        "moviesDF = pd.read_csv(os.path.join(MOVIELENS_DIR, 'u.item'), sep='|', names=fieldsMovies, encoding='latin-1')\n",
        "moviesDF[moviesDF.movieID == 257]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>movieID</th>\n",
              "      <th>movieTitle</th>\n",
              "      <th>releaseDate</th>\n",
              "      <th>videoReleaseDate</th>\n",
              "      <th>IMDbURL</th>\n",
              "      <th>unknown</th>\n",
              "      <th>action</th>\n",
              "      <th>adventure</th>\n",
              "      <th>animation</th>\n",
              "      <th>childrens</th>\n",
              "      <th>comedy</th>\n",
              "      <th>crime</th>\n",
              "      <th>documentary</th>\n",
              "      <th>drama</th>\n",
              "      <th>fantasy</th>\n",
              "      <th>filmNoir</th>\n",
              "      <th>horror</th>\n",
              "      <th>musical</th>\n",
              "      <th>mystery</th>\n",
              "      <th>romance</th>\n",
              "      <th>sciFi</th>\n",
              "      <th>thriller</th>\n",
              "      <th>war</th>\n",
              "      <th>western</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>256</th>\n",
              "      <td>257</td>\n",
              "      <td>Men in Black (1997)</td>\n",
              "      <td>04-Jul-1997</td>\n",
              "      <td>NaN</td>\n",
              "      <td>http://us.imdb.com/M/title-exact?Men+in+Black+...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     movieID           movieTitle  releaseDate  ...  thriller war  western\n",
              "256      257  Men in Black (1997)  04-Jul-1997  ...         0   0        0\n",
              "\n",
              "[1 rows x 24 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIdq9cC7quNu",
        "colab_type": "code",
        "outputId": "92c22310-dc55-4771-efd2-7462f5034fa5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "#by using movie similarity score, see which movies is more similar than other \n",
        "train_matrix = dataPreprocessor(rating_df, num_users, num_items)\n",
        "ii_similarity = SimBasedRecSys.cosine(train_matrix.transpose())#movie as roll\n",
        "\n",
        "for id in [225, 257, 1129]:\n",
        "    top5_index = np.argsort(ii_similarity[id-1])[-6:-1][::-1] #id starts with 0, argsort from big to small, sort backwards, [::-1] sort from big to small \n",
        "    name = moviesDF.movieTitle[id-1]\n",
        "    print(\"----- movie %s-------\" % name)\n",
        "    for top_index in top5_index:\n",
        "        print(\"%s: %f\" % (moviesDF.movieTitle[top_index], ii_similarity[id-1][top_index]))\n",
        "    \n",
        "    print('\\n')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----- movie 101 Dalmatians (1996)-------\n",
            "Jack (1996): 0.447883\n",
            "Twister (1996): 0.441882\n",
            "Willy Wonka and the Chocolate Factory (1971): 0.423295\n",
            "Independence Day (ID4) (1996): 0.420642\n",
            "Toy Story (1995): 0.409386\n",
            "\n",
            "\n",
            "----- movie Men in Black (1997)-------\n",
            "Return of the Jedi (1983): 0.640674\n",
            "Star Wars (1977): 0.634035\n",
            "Independence Day (ID4) (1996): 0.623008\n",
            "Toy Story (1995): 0.591641\n",
            "Star Trek: First Contact (1996): 0.586286\n",
            "\n",
            "\n",
            "----- movie Chungking Express (1994)-------\n",
            "Hard Eight (1996): 0.400012\n",
            "I Shot Andy Warhol (1996): 0.340117\n",
            "Fille seule, La (A Single Girl) (1995): 0.332347\n",
            "Hate (Haine, La) (1995): 0.330868\n",
            "Young Poisoner's Handbook, The (1995): 0.327019\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jnRDOuH4zdvF"
      },
      "source": [
        "### (b)\n",
        "The movie recommended are of smiliar types. The similarity score is based on all users' ratings of movies and is determined by if they treat both movies in the same way (rate the same score). For people who hate \"Man in Black\", they are likely to rate similar types of movie low, for example, Sci-Fi and adventure movies."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QiSiG2UrzdvK"
      },
      "source": [
        "## Q7"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sH63iq22zdvK"
      },
      "source": [
        "### (a)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NeUK2ZR5zdvM",
        "outputId": "745a5be7-2ed4-48e8-de90-3e991a402608",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        }
      },
      "source": [
        "matrix = dataPreprocessor(rating_df, num_users, num_items)\n",
        "matrix[matrix.nonzero()] = 1\n",
        "count = np.sum(matrix, axis=1)\n",
        "#count = np.hstack(count)\n",
        "plt.hist(count, bins='auto')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([331., 152.,  75.,  68.,  53.,  52.,  35.,  35.,  29.,  24.,  17.,\n",
              "         18.,  12.,   9.,   7.,   8.,   5.,   3.,   1.,   1.,   3.,   1.,\n",
              "          1.,   0.,   0.,   0.,   1.,   0.,   1.,   0.,   1.]),\n",
              " array([ 20.        ,  43.12903226,  66.25806452,  89.38709677,\n",
              "        112.51612903, 135.64516129, 158.77419355, 181.90322581,\n",
              "        205.03225806, 228.16129032, 251.29032258, 274.41935484,\n",
              "        297.5483871 , 320.67741935, 343.80645161, 366.93548387,\n",
              "        390.06451613, 413.19354839, 436.32258065, 459.4516129 ,\n",
              "        482.58064516, 505.70967742, 528.83870968, 551.96774194,\n",
              "        575.09677419, 598.22580645, 621.35483871, 644.48387097,\n",
              "        667.61290323, 690.74193548, 713.87096774, 737.        ]),\n",
              " <a list of 31 Patch objects>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONeWSqmi9b_O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "36ea069c-6083-43fd-f20c-75d50c6d5960"
      },
      "source": [
        "thre = 66\n",
        "# train_matrix = dataPreprocessor(rating_df, num_users, num_items)\n",
        "# user_id_list_above_thre = [i for i in range(len(count)) if count[i] >= thre] #ID-1\n",
        "# matrix = pd.DataFrame(matrix)\n",
        "# user_id_list_below_thre = [ind for ind in matrix.index.tolist() if ind not in user_id_list_above_thre] #ID-1\n",
        "train_matrix_above = train_matrix[count>=thre]\n",
        "train_matrix_below = train_matrix[count<thre]\n",
        "train_matrix_above.shape\n",
        "train_matrix_below.shape"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(477, 1682)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j11y2mXbFIM3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict_uu(train_matrix): \n",
        "            \n",
        "    uu_similarity = SimBasedRecSys.cosine(train_matrix)\n",
        "    temp_matrix = np.zeros(train_matrix.shape)\n",
        "    temp_matrix[train_matrix.nonzero()] = 1\n",
        "    \n",
        "    normalizer = np.matmul(uu_similarity, temp_matrix) #number of users*number of items\n",
        "    normalizer[normalizer == 0] = 1e-5 #10**-5\n",
        "            \n",
        "    predictionMatrix = np.matmul(uu_similarity, train_matrix)/normalizer \n",
        "           \n",
        "    useraverage = np.sum(train_matrix, axis=1)/(np.sum(temp_matrix, axis=1) + 1e-5) #axis=1 tuple横着加 sum of user rating/#user\n",
        "    columns = np.sum(predictionMatrix, axis=0) #sum of ratings for each item #1*number of items\n",
        "         \n",
        "    predictionMatrix[:, columns==0] = predictionMatrix[:, columns==0] + np.expand_dims(useraverage, axis=1)\n",
        "                                             #columns这个matrix数列里数字是0的index对应的predictionMatrix\n",
        "    return predictionMatrix\n",
        "        \n",
        "def predict_ii(train_matrix):\n",
        "    \n",
        "    train_matrix = train_matrix.T\n",
        "    ii_similarity = SimBasedRecSys.cosine(train_matrix)  #similarity of items\n",
        "             \n",
        "    temp_matrix = np.zeros(train_matrix.shape)\n",
        "    temp_matrix[train_matrix.nonzero()] = 1\n",
        "            \n",
        "    normalizer = np.matmul(ii_similarity, temp_matrix) #number of users*number of items\n",
        "    normalizer[normalizer == 0] = 1e-5 #10**-5\n",
        "    \n",
        "    predictionMatrix = np.matmul(ii_similarity, train_matrix)/normalizer #why do we need a normalizer?\n",
        "           \n",
        "    itemaverage = np.sum(train_matrix, axis=1)/(np.sum(temp_matrix, axis=1) + 1e-5) #axis=1 tuple横着加 sum of user rating/#user\n",
        "    columns = np.sum(predictionMatrix, axis=0) #sum of ratings for each item #1*number of items\n",
        "\n",
        "    predictionMatrix[:, columns==0] = predictionMatrix[:, columns==0] + np.expand_dims(itemaverage, axis=1)\n",
        "                                             #columns这个matrix数列里数字是0的index对应的predictionMatrix\n",
        "\n",
        "    return predictionMatrix.T\n",
        "\n",
        "\n",
        "def rmse(prediction, real):\n",
        "    prediction = prediction[real.nonzero()].flatten() \n",
        "    real = real[real.nonzero()].flatten()\n",
        "    return sqrt(mean_squared_error(prediction, real))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XS5z18RpLJh5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "above_thre_uu = predict_uu(train_matrix_above)\n",
        "below_thre_uu = predict_uu(train_matrix_below)\n",
        "above_thre_ii = predict_ii(train_matrix_above)\n",
        "below_thre_ii = predict_ii(train_matrix_below)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDxuaWeCPnGn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rmse_above_thre_uu = rmse(above_thre_uu, train_matrix_above)\n",
        "rmse_below_thre_uu = rmse(below_thre_uu, train_matrix_below)\n",
        "rmse_above_thre_ii = rmse(above_thre_ii, train_matrix_above)\n",
        "rmse_below_thre_ii = rmse(below_thre_ii, train_matrix_below)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKwd_-04QJ_G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "edbf2d2a-0e72-439d-b278-5272d48f53f4"
      },
      "source": [
        "print('User based: above threshold: %f, below threshold: %f' % (rmse_above_thre_uu,rmse_below_thre_uu ))\n",
        "print('Item based: above threshold: %f, below threshold: %f' % (rmse_above_thre_ii,rmse_below_thre_ii))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "User based: above threshold: 0.949731, below threshold: 0.872217\n",
            "Item based: above threshold: 0.990059, below threshold: 0.875874\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m6nuS6cDRxqu",
        "colab_type": "text"
      },
      "source": [
        "For both user based method and item based method, the model with users with a large to moderate number of ratings did better than that with a few. Becase the similarity is determined by if users treat both movies in the same way (rate the same score). This requires a large number of item data for each user in order for the model to have a better performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "collapsed": true,
        "id": "G2V2BXb-zdvQ"
      },
      "source": [
        "# Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sjWEiRzezdvR",
        "colab": {}
      },
      "source": [
        "# Constants for validation only\n",
        "ROW_NUM = 943\n",
        "COL_NUM = 1682\n",
        "RATING_COL = 'rating'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mqZ3DOSHzdvV"
      },
      "source": [
        "### dataPreprocessor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "A4jypcIRzdvY",
        "colab": {}
      },
      "source": [
        "def validateDataPreprocessor(path=MOVIELENS_DIR, getData=getData, getMatrix=CrossValidation.getMatrix):\n",
        "    validation_df = getData(MOVIELENS_DIR, 'u1.test')\n",
        "    try:\n",
        "        matrix = getMatrix(validation_df, ROW_NUM, COL_NUM, RATING_COL)\n",
        "    except:\n",
        "        print('dataPreprocessor function has error')\n",
        "        return\n",
        "    try:\n",
        "        assert(matrix.shape == (ROW_NUM,COL_NUM)),\\\n",
        "        \"Shape of matrix{0} doesn't match predefined shape (943,1682)\".format(matrix.shape)\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "    return validation_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "G_Tc_IVazdvd",
        "colab": {}
      },
      "source": [
        "validation_df = validateDataPreprocessor()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4_PmoIrWzdvf"
      },
      "source": [
        "## Baseline Recommendation Systems"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zGA1yZ9hzdvf"
      },
      "source": [
        "### Popularity Based Recommendation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "O_ySapEazdvg",
        "colab": {}
      },
      "source": [
        "def validatePopularityRecSys(validation_df=validation_df, BaseLineRecSys = BaseLineRecSys):\n",
        "    popularity_recsys = BaseLineRecSys('popularity')\n",
        "    try:\n",
        "        popularity_recsys.predict_all(validation_df, ROW_NUM, COL_NUM)\n",
        "    except Exception as e:        \n",
        "        print('popularity function has error')\n",
        "        print(e)\n",
        "        return\n",
        "    try:\n",
        "        predictionMatrix = popularity_recsys.getModel()\n",
        "        assert(predictionMatrix.shape == (ROW_NUM, COL_NUM)),\\\n",
        "        \"Shape of matrix{0} doesn't match predefined shape ({1},{2})\"\\\n",
        "        .format(predictionMatrix.shape,ROW_NUM, COL_NUM)\n",
        "    except Exception as e:\n",
        "        print(e)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TyCJ1Be0zdvi",
        "outputId": "3548f093-524e-4d85-d1e7-0bffb3d2473f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "validatePopularityRecSys()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n",
            "calculated 800 users\n",
            "calculated 900 users\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4g1wwQpxzdvp"
      },
      "source": [
        "### User Average Based Recommendation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "K1KASm63zdvp",
        "colab": {}
      },
      "source": [
        "def validateUserAverRecSys(validation_df=validation_df, BaseLineRecSys = BaseLineRecSys):\n",
        "    useraverage_recsys = BaseLineRecSys('useraverage')\n",
        "    try:\n",
        "        useraverage_recsys.predict_all(validation_df, ROW_NUM, COL_NUM)\n",
        "    except:\n",
        "        print('useraverage function has error')\n",
        "        return\n",
        "    try:\n",
        "        predictionMatrix = useraverage_recsys.getModel()\n",
        "        assert(predictionMatrix.shape == (ROW_NUM, COL_NUM)),\\\n",
        "        \"Shape of matrix{0} doesn't match predefined shape ({1},{2})\"\\\n",
        "        .format(predictionMatrix.shape,ROW_NUM, COL_NUM)\n",
        "    except Exception as e:\n",
        "        print(e)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5A36VedIzdvs",
        "outputId": "d4301e08-2429-4672-bd22-a4acd7a5e75b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "validateUserAverRecSys()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n",
            "calculated 800 users\n",
            "calculated 900 users\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vlxJxooBzdvx"
      },
      "source": [
        "## Similary Based Recommendation Systems"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cvmIFAXXzdvy"
      },
      "source": [
        "### Euclidean Similarity Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "z74E1PMRzdvy",
        "colab": {}
      },
      "source": [
        "def validateEuclidean(validation_df=validation_df, getMatrix=CrossValidation.getMatrix):\n",
        "    matrix = getMatrix(validation_df, ROW_NUM, COL_NUM, RATING_COL)\n",
        "    try:\n",
        "        sim_matrix = SimBasedRecSys.euclidean(matrix)\n",
        "        assert(sim_matrix.shape == (ROW_NUM, ROW_NUM)),\\\n",
        "        \"Shape of matrix{0} doesn't match predefined shape ({1},{2})\"\\\n",
        "        .format(sim_matrix.shape,ROW_NUM,ROW_NUM)\n",
        "        assert(np.any(sim_matrix <= 1)),\\\n",
        "               \"Exist similarity value that is not less or equal to 1.\"\n",
        "    except Exception as e:\n",
        "        print(e)        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qqzEUppEzdv4",
        "colab": {}
      },
      "source": [
        "validateEuclidean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UnBQxFEPzdv6"
      },
      "source": [
        "### Customized Similarity Function (test somethingelse function)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mPpRR_hjzdv6",
        "colab": {}
      },
      "source": [
        "def validateCustomizedSim(validation_df=validation_df, getMatrix=CrossValidation.getMatrix):\n",
        "    matrix = getMatrix(validation_df, ROW_NUM, COL_NUM, RATING_COL)\n",
        "    try:\n",
        "        sim_matrix = SimBasedRecSys.somethingelse(matrix)\n",
        "        assert(sim_matrix.shape == (ROW_NUM, ROW_NUM)),\\\n",
        "        \"Shape of matrix{0} doesn't match predefined shape ({1},{2})\"\\\n",
        "        .format(sim_matrix.shape,ROW_NUM,ROW_NUM)\n",
        "        assert(np.any(sim_matrix <= 1)),\\\n",
        "               \"Exist similarity value that is not less or equal to 1.\"\n",
        "    except Exception as e:\n",
        "        print(e) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4uGIWOS7zdv8",
        "colab": {}
      },
      "source": [
        "validateCustomizedSim()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DMKOOB6mzdwB"
      },
      "source": [
        "### User-User Similarity Based Recommendation System"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "t_V0gdBTzdwB",
        "colab": {}
      },
      "source": [
        "def validateUUSimBasedRecSys(validation_df=validation_df, dataPreprocessor=dataPreprocessor):\n",
        "    try:\n",
        "        user_cosine_recsys = SimBasedRecSys('user','cosine', dataPreprocessor)\n",
        "    except:\n",
        "        print(\"Got error when instantiate SimBasedRecSys\")\n",
        "        return\n",
        "    \n",
        "    try:\n",
        "        user_cosine_recsys.predict_all(validation_df, ROW_NUM, COL_NUM)\n",
        "        predictionMatrix = user_cosine_recsys.getModel()\n",
        "        assert(predictionMatrix.shape == (ROW_NUM, COL_NUM)),\\\n",
        "        \"Shape of matrix{0} doesn't match predefined shape ({1},{2})\"\\\n",
        "        .format(predictionMatrix.shape,ROW_NUM, COL_NUM)\n",
        "    except Exception as e:\n",
        "        print(e)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KkausxHizdwE",
        "colab": {}
      },
      "source": [
        "validateUUSimBasedRecSys()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1IAGUMvwzdwH"
      },
      "source": [
        "### Item-Item Similarity Based Recommendation System"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "H-j6pDB3zdwH",
        "colab": {}
      },
      "source": [
        "def validateIISimBasedRecSys(validation_df=validation_df, dataPreprocessor=dataPreprocessor):\n",
        "    try:\n",
        "        user_cosine_recsys = SimBasedRecSys('item','cosine', dataPreprocessor)\n",
        "    except:\n",
        "        print(\"Got error when instantiate SimBasedRecSys\")\n",
        "        return\n",
        "    \n",
        "    try:\n",
        "        user_cosine_recsys.predict_all(validation_df, ROW_NUM, COL_NUM)\n",
        "        predictionMatrix = user_cosine_recsys.getModel()\n",
        "        assert(predictionMatrix.shape == (ROW_NUM, COL_NUM)),\\\n",
        "        \"Shape of matrix{0} doesn't match predefined shape ({1},{2})\"\\\n",
        "        .format(predictionMatrix.shape,ROW_NUM, COL_NUM)\n",
        "    except Exception as e:\n",
        "        print(e)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TjAlZnpYzdwK",
        "colab": {}
      },
      "source": [
        "validateIISimBasedRecSys()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FYo97yYTCKbI"
      },
      "source": [
        "### Probabilistic Matrix Factorization Recommendation System"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rB1_H8mxzdwO",
        "colab": {}
      },
      "source": [
        "def validatePMFRecSys(validation_df=validation_df):\n",
        "    try:\n",
        "        pmf = PMFRecSys()\n",
        "        pmf.set_params({\"num_feat\": 10, \"epsilon\": 1, \"_lambda\": 0.1, \"momentum\": 0.8, \"maxepoch\": 1, \"num_batches\": 100,\n",
        "                \"batch_size\": 1000, 'test_mode':True})\n",
        "        pmf.predict_all(rating_df, ROW_NUM, COL_NUM)\n",
        "    except:\n",
        "        print(\"Got error when instantiate PMFRecSys\")\n",
        "        return\n",
        "    \n",
        "    try:\n",
        "        pmf.predict_all(validation_df, ROW_NUM, COL_NUM)\n",
        "        W_item, W_user = pmf.w_Item, pmf.w_User\n",
        "        assert(W_item.shape == (COL_NUM+1, 10) and W_user.shape == (ROW_NUM+1, 10)),\\\n",
        "        \"Shape of w_Item and W_User doesn't match predefined shape\"\n",
        "    except Exception as e:\n",
        "        print(e)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BW82XMfdzdwQ",
        "colab": {}
      },
      "source": [
        "validatePMFRecSys(validation_df=validation_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ldve7N_0DRF4",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}